[general]
experiment_name = "wine_100runs_learning-rate_3mv-features_custom-loss"
experiment_variable = "optimizer_params"
missing_percent = [0.0, 0.15, 0.0, 0.0, 0.2, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
missing_value_mask = -1
random_seed = false
use_toy_data = false

[toy_data]
n_features = 3
n_samples = [50, 100, 50]
centers = [[1, 5, 1], [7, 12, 9], [10, 2, 5]]
cluster_std = 1.5

[DBSCAN]
eps = ""
min_samples = ""

[RQ2]
pred_features = 1
runs = 100

[regressor_param]
#optimizer_fn = torch.optim.Adam
#scheduler_fn = torch.optim.lr_scheduler.StepLR
#scheduler_params = {'step_size': 2, 'gamma': 0.9}
optimizer_params = [0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1.0]
#mask_type = "entmax"

[training]
train_val_split = 0.75
cl_weights = [0.5, 1.0, 0.0001] # Explanation: [RMSE, KLDiv, Cluster-Mean-Loss]

[model_param]
max_epochs = 250
patience = 50
eval_metric = ["custom_loss"]

[plots]
dpi = 300